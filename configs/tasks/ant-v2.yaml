ENVIRONMENT:
    MAX_EPISODE_STEPS: 150

SIMULATOR:
  TYPE: Ant-v2-sim
  AGENTS: ['AGENT_0']
  AGENT_0:  
    # Agent setup
    HEIGHT: 1.5
    IS_SET_START_STATE: False
    RADIUS: 0.1
    SENSORS: ['HEAD_RGB_SENSOR', 'DEPTH_SENSOR', 'THIRD_SENSOR']
    START_POSITION: [0, -0.2, 0]
    START_ROTATION: [0, 0, 1.6, 1]
  HEAD_RGB_SENSOR:
        WIDTH: 128
        HEIGHT: 128
  THIRD_SENSOR:
        WIDTH: 512
        HEIGHT: 512
        POSITION: [-2,2,0]
        HFOV: 90
        ORIENTATION: [-0.5, -1.57,0.0]
  DEPTH_SENSOR:
        WIDTH: 128
        HEIGHT: 128
        MIN_DEPTH: 0.0
        MAX_DEPTH: 10.0
        NORMALIZE_DEPTH: True
  ROBOT_URDF: data/robots/ant.urdf
  
  #NOTE: control frequency in Hz. Physics stepped at 1/CTRL_FREQ
  CTRL_FREQ: 30

  # LEG TARGET
  LEG_TARGET_STATE: [0.0, -1.0, 0.0, -1.0, 0.0, 1.0, 0.0, 1.0]

  #Target vector for the ant to progress towards, vector must be normalized
  TARGET_VECTOR: "RANDOM" #[1.0, 0.0, 0.0]
  ANT_START_ROTATION: 1.57 # Does not work properly
  TARGET_SPEED: 1

  #NOTE: these below are unused
  #AC_FREQ_RATIO: 4

  # LOAD_OBSTACLES: True # Loads obstacles for the ant to avoid

  HABITAT_SIM_V0:
    ALLOW_SLIDING: True
    ENABLE_PHYSICS: True
    GPU_DEVICE_ID: 0
    GPU_GPU: False
    PHYSICS_CONFIG_FILE: ./data/default.physics_config.json

TASK:
  TYPE: Ant-v2-task
  ANT_OBSERVATION_SPACE_SENSOR:
    TYPE: "AntObservationSpaceSensor"
    #list of possible terms to add and their parameters
    PERIODIC_TIME:
      SIZE: 1
    BASE_POSITION:
      SIZE: 3
    BASE_QUATERNION:
      SIZE: 4
    EGOCENTRIC_TARGET_VECTOR:
      SIZE: 3
    EGOCENTRIC_UPWARDS_VECTOR:
      SIZE: 3
    BASE_LIN_VEL:
      SIZE: 3
    EGOCENTRIC_BASE_LIN_VEL:
      SIZE: 3
    BASE_ANG_VEL:
      SIZE: 3
    EGOCENTRIC_BASE_ANG_VEL:
      SIZE: 3
    JOINT_POS:
      SIZE: 8
    JOINT_MOTOR_POS:
      SIZE: 8
    JOINT_VEL:
      SIZE: 8
    JOINT_TARGET: # Sets a target pose for the ant; relevant when rewarding the ant for closeness to this pose
      SIZE: 8
      POSE: [0.0, -1.0, 0.0, -1.0, 0.0, 1.0, 0.0, 1.0]
    #TODO: add terms for ego centric up(3), forward(3), target_velocity(3)
    # may want ego centric locations of feet, contact information of feet (force or boolean), may want history 
    #NOTE: list active terms here:
    ACTIVE_TERMS: ["PERIODIC_TIME", "EGOCENTRIC_TARGET_VECTOR", "EGOCENTRIC_UPWARDS_VECTOR", "EGOCENTRIC_BASE_LIN_VEL", "EGOCENTRIC_BASE_ANG_VEL", "JOINT_POS","JOINT_MOTOR_POS","JOINT_VEL","JOINT_TARGET"] # need to update joint target, add history of actions
    

  SENSORS: ["ANT_OBSERVATION_SPACE_SENSOR"]

  X_LOCATION:
    TYPE: "XLocation"
  VECTOR_ROOT_DELTA:
    TYPE: "VectorRootDelta"
  JOINT_STATE_ERROR:
    TYPE: "JointStateError"
    #normalize return such that max error is -1 using joint limits 
    NORMALIZED: False
  JOINT_STATE_MAX_ERROR:
    TYPE: "JointStateMaxError"
  JOINT_STATE_PRODUCT_ERROR:
    #measure is the product of inverted normalized terms (i.e. max for each joint is 1, min is 0, total is product) 
    TYPE: "JointStateProductError"
  ACTIVE_CONTACTS:
    TYPE: "ActiveContacts"
  ACTION_COST:
    TYPE: "ActionCost"
  VELOCITY_ALIGNMENT:
    TYPE: "VelocityAlignment"
  SPEED_TARGET:
    TYPE: "SpeedTarget"
  ORTHOGONAL_VELOCITY:
    TYPE: "OrthogonalVelocity"
  COMPOSITE_ANT_REWARD:
    TYPE: "CompositeAntReward"
    #setting up the defaults here
    COMPONENTS: ["ACTION_COST","JOINT_STATE_ERROR","X_LOCATION"]
    WEIGHTS: [1.0, 1.0, 10.0]
  UPRIGHT_ORIENTATION_DEVIATION_VALUE:
    TYPE: "VectorAlignmentValue"
    UUID: "UPRIGHT_ORIENTATION_DEVIATION_VALUE"
    LOCAL_VECTOR: [0.0, 1.0, 0.0]
    GLOBAL_VECTOR: [0.0, 1.0, 0.0]
  FORWARD_ORIENTATION_DEVIATION_VALUE:
    TYPE: "VectorAlignmentValue"
    UUID: "FORWARD_ORIENTATION_DEVIATION_VALUE"
    LOCAL_VECTOR: [1.0, 0.0, 0.0]
    GLOBAL_VECTOR: "TARGET"
  MEASUREMENTS: ["X_LOCATION", "VELOCITY_ALIGNMENT", "SPEED_TARGET", "VECTOR_ROOT_DELTA", "JOINT_STATE_ERROR", "JOINT_STATE_MAX_ERROR", "ACTIVE_CONTACTS", "ACTION_COST", "UPRIGHT_ORIENTATION_DEVIATION_VALUE", "FORWARD_ORIENTATION_DEVIATION_VALUE", "ORTHOGONAL_VELOCITY", "COMPOSITE_ANT_REWARD"]

  ACTIONS:
    LEG_ACTION:
      TYPE: "LegAction"
      LEG_CONTROLLER: "LegRelPosAction"
      LEG_JOINT_DIMENSIONALITY: 8
      DELTA_POS_LIMIT: 0.1
    LEG_ACTION_ABS:
      TYPE: "LegAction"
      LEG_CONTROLLER: "LegAbsPosAction"
      LEG_JOINT_DIMENSIONALITY: 8
    LEG_ACTION_SYMMETRICAL:
      TYPE: "LegAction"
      LEG_CONTROLLER: "LegRelPosActionSymmetrical"
      LEG_JOINT_DIMENSIONALITY: 4
      DELTA_POS_LIMIT: 0.1
    LEG_ACTION_GAIT_DEVIATION:
      TYPE: "LegAction"
      LEG_CONTROLLER: "LegRelPosActionGaitDeviation"
      LEG_JOINT_DIMENSIONALITY: 8
      DELTA_POS_LIMIT: 0.3
  POSSIBLE_ACTIONS:
    - LEG_ACTION_GAIT_DEVIATION

DATASET:
  TYPE: AntV2Dataset-v0