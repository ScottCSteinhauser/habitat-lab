ENVIRONMENT:
    MAX_EPISODE_STEPS: 150

SIMULATOR:
  TYPE: Ant-v2-sim
  AGENTS: ['AGENT_0']
  AGENT_0:  
    # Agent setup
    HEIGHT: 1.5
    IS_SET_START_STATE: False
    RADIUS: 0.1
    SENSORS: ['HEAD_RGB_SENSOR', 'DEPTH_SENSOR', 'THIRD_SENSOR']
    START_POSITION: [0, -0.2, 0]
    START_ROTATION: [0, 0, 1.6, 1]
  HEAD_RGB_SENSOR:
        WIDTH: 128
        HEIGHT: 128
  THIRD_SENSOR:
        WIDTH: 512
        HEIGHT: 512
        POSITION: [-2,2,0]
        HFOV: 90
        ORIENTATION: [-0.5, -1.57,0.0]
  DEPTH_SENSOR:
        WIDTH: 128
        HEIGHT: 128
        MIN_DEPTH: 0.0
        MAX_DEPTH: 10.0
        NORMALIZE_DEPTH: True
  ROBOT_URDF: data/robots/ant.urdf
  
  #NOTE: control frequency in Hz. Physics stepped at 1/CTRL_FREQ
  CTRL_FREQ: 30

  # LEG TARGET
  LEG_TARGET_STATE: "NATURAL_GAIT" # [0.0, -1.0, 0.0, -1.0, 0.0, 1.0, 0.0, 1.0] # 

  #Target vector for the ant to progress towards, vector must be normalized
  TARGET_VECTOR: [1.0, 0.0, 0.0] # "RANDOM" #
  ANT_START_ROTATION: 1.57 # Does not work properly
  TARGET_SPEED: 1

  #NOTE: these below are unused
  #AC_FREQ_RATIO: 4

  LOAD_OBSTACLES: False # Loads obstacles for the ant to avoid
  LOAD_CORRIDOR: False # Loads obstacles for the ant to avoid

  HABITAT_SIM_V0:
    ALLOW_SLIDING: True
    ENABLE_PHYSICS: True
    GPU_DEVICE_ID: 0
    GPU_GPU: False
    PHYSICS_CONFIG_FILE: ./data/default.physics_config.json

TASK:
  TYPE: Ant-v2-task
  ANT_OBSERVATION_SPACE_SENSOR:
    TYPE: "AntObservationSpaceSensor"
    #list of possible terms to add and their parameters
    PERIODIC_TIME:
      SIZE: 1
    BASE_POSITION:
      SIZE: 3
    BASE_QUATERNION:
      SIZE: 4
    EGOCENTRIC_TARGET_VECTOR:
      SIZE: 3
    EGOCENTRIC_UPWARDS_VECTOR:
      SIZE: 3
    BASE_LIN_VEL:
      SIZE: 3
    EGOCENTRIC_BASE_LIN_VEL:
      SIZE: 3
    BASE_ANG_VEL:
      SIZE: 3
    EGOCENTRIC_BASE_ANG_VEL:
      SIZE: 3
    JOINT_POS:
      SIZE: 8
    JOINT_MOTOR_POS:
      SIZE: 8
    JOINT_VEL:
      SIZE: 8
    JOINT_TARGET: # Sets a target pose for the ant; relevant when rewarding the ant for closeness to this pose
      SIZE: 8
      POSE: [0.0, -1.0, 0.0, -1.0, 0.0, 1.0, 0.0, 1.0]
    NEXT_JOINT_TARGET:
      SIZE: 8
      POSE: [0.0, -1.0, 0.0, -1.0, 0.0, 1.0, 0.0, 1.0]
    JOINT_POSITION_HISTORY:
      SIZE: 8
      NUM_STEPS: 3 # number of previous steps to include in history
    ACTION_HISTORY:
      SIZE: 8
      NUM_STEPS: 3 # number of previous steps to include in history
    LEG_CONTACTS:
      SIZE: 4
    EGOCENTRIC_LEG_POSITIONS: # 4 positions of the ant's feet in egocentric space
      SIZE: 12
    #NOTE: list active terms here:
    ACTIVE_TERMS: ["PERIODIC_TIME", "LEG_CONTACTS", "EGOCENTRIC_LEG_POSITIONS", "EGOCENTRIC_TARGET_VECTOR", "EGOCENTRIC_UPWARDS_VECTOR", "EGOCENTRIC_BASE_LIN_VEL", "EGOCENTRIC_BASE_ANG_VEL", "JOINT_POS","JOINT_MOTOR_POS","JOINT_VEL","JOINT_TARGET","NEXT_JOINT_TARGET","JOINT_POSITION_HISTORY","ACTION_HISTORY"] # need to update joint target, add history of actions

  SENSORS: ["ANT_OBSERVATION_SPACE_SENSOR"]

  X_LOCATION:
    TYPE: "XLocation"
  VECTOR_ROOT_DELTA:
    TYPE: "VectorRootDelta"
  JOINT_STATE_ERROR:
    TYPE: "JointStateError"
    #normalize return such that max error is -1 using joint limits 
    NORMALIZED: False
  JOINT_STATE_MAX_ERROR:
    TYPE: "JointStateMaxError"
  JOINT_STATE_PRODUCT_ERROR:
    #measure is the product of inverted normalized terms (i.e. max for each joint is 1, min is 0, total is product) 
    TYPE: "JointStateProductError"
  ACTIVE_CONTACTS:
    TYPE: "ActiveContacts"
  ACTION_COST_PRODUCT:
    TYPE: "ActionCost"
    UUID: "ACTION_COST_PRODUCT"
    MODIFIER: "NORMALIZED_PRODUCT"
  ACTION_COST_SUM:
    TYPE: "ActionCost"
    UUID: "ACTION_COST_SUM"
    MODIFIER: "NORMALIZED_SUM"
  ACTION_SMOOTHNESS:
    TYPE: "ActionSmoothness"
    WINDOW: 3
  VELOCITY_ALIGNMENT:
    TYPE: "VelocityAlignment"
  SPEED_TARGET:
    TYPE: "SpeedTarget"
  ORTHOGONAL_VELOCITY:
    TYPE: "OrthogonalVelocity"
  COMPOSITE_ANT_REWARD:
    TYPE: "CompositeAntReward"
    #setting up the defaults here
    COMPONENTS: ["ACTION_COST_PRODUCT","JOINT_STATE_ERROR","X_LOCATION"]
    #add additional requirements such as binary termination measures here:
    ADDITIONAL_REQUIREMENTS: []
    WEIGHTS: [1.0, 1.0, 10.0]
  UPRIGHT_ORIENTATION_DEVIATION_VALUE:
    TYPE: "VectorAlignmentValue"
    UUID: "UPRIGHT_ORIENTATION_DEVIATION_VALUE"
    LOCAL_VECTOR: [0.0, 1.0, 0.0]
    GLOBAL_VECTOR: [0.0, 1.0, 0.0]
    MODIFIER: "NONE"
  FORWARD_ORIENTATION_DEVIATION_VALUE:
    TYPE: "VectorAlignmentValue"
    UUID: "FORWARD_ORIENTATION_DEVIATION_VALUE"
    LOCAL_VECTOR: [1.0, 0.0, 0.0]
    GLOBAL_VECTOR: "TARGET"
    MODIFIER: "NONE"
  FORWARD_ORIENTATION_DEVIATION_VALUE_SQUARED:
    TYPE: "VectorAlignmentValue"
    UUID: "FORWARD_ORIENTATION_DEVIATION_VALUE_SQUARED"
    LOCAL_VECTOR: [1.0, 0.0, 0.0]
    GLOBAL_VECTOR: "TARGET"
    MODIFIER: "SQUARED"
  ORIENTATION_TERMINATE:
    TYPE: "OrientationTerminate"
  MEASUREMENTS: ["X_LOCATION", "VELOCITY_ALIGNMENT", "SPEED_TARGET", "VECTOR_ROOT_DELTA", "JOINT_STATE_ERROR", "JOINT_STATE_MAX_ERROR","JOINT_STATE_PRODUCT_ERROR", "ACTIVE_CONTACTS", "ACTION_COST_PRODUCT", "ACTION_COST_SUM", "ACTION_SMOOTHNESS", "UPRIGHT_ORIENTATION_DEVIATION_VALUE", "FORWARD_ORIENTATION_DEVIATION_VALUE","FORWARD_ORIENTATION_DEVIATION_VALUE_SQUARED", "ORTHOGONAL_VELOCITY", "ORIENTATION_TERMINATE", "COMPOSITE_ANT_REWARD"]

  ACTIONS:
    LEG_ACTION:
      TYPE: "LegAction"
      LEG_CONTROLLER: "LegRelPosAction"
      LEG_JOINT_DIMENSIONALITY: 8
      DELTA_POS_LIMIT: 0.1
    LEG_ACTION_ABS:
      TYPE: "LegAction"
      LEG_CONTROLLER: "LegAbsPosAction"
      LEG_JOINT_DIMENSIONALITY: 8
    LEG_ACTION_SYMMETRICAL:
      TYPE: "LegAction"
      LEG_CONTROLLER: "LegRelPosActionSymmetrical"
      LEG_JOINT_DIMENSIONALITY: 4
      DELTA_POS_LIMIT: 0.1
    LEG_ACTION_GAIT_DEVIATION:
      TYPE: "LegAction"
      LEG_CONTROLLER: "LegRelPosActionGaitDeviation"
      LEG_JOINT_DIMENSIONALITY: 8
      DELTA_POS_LIMIT: 0.3
  POSSIBLE_ACTIONS:
    - LEG_ACTION_ABS

DATASET:
  TYPE: AntV2Dataset-v0